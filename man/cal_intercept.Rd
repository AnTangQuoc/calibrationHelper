% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prob-cal_intercept.r
\name{cal_intercept}
\alias{cal_intercept}
\alias{cal_intercept.data.frame}
\alias{cal_intercept_vec}
\title{Calibration-in-the-large}
\usage{
cal_intercept(data, ...)

\method{cal_intercept}{data.frame}(
  data,
  truth,
  ...,
  estimator = NULL,
  na_rm = TRUE,
  case_weights = NULL,
  event_level = "first"
)

cal_intercept_vec(
  truth,
  estimate,
  estimator = NULL,
  na_rm = TRUE,
  event_level = "first",
  case_weights = NULL
)
}
\description{
\code{cal_intercept()} is a metric that computes the calibration-in-the-large.
}
\details{
Calibration-in-the-large compares the average predicted risk with the
overall event rate. When the average predicted risk is higher than the
overall event rate, the model overestimates risk in general. Conversely,
underestimation occurs when the observed event rate is higher than the
average predicted risk. The calibration intercept, which is an assessment
of calibration-in-the-large, has a target value of 0; negative values
suggest overestimation, whereas positive values suggest underestimation.
}
\references{
Van Calster, B., McLernon, D.J., van Smeden, M. et al. Calibration:
the Achilles heel of predictive analytics. BMC Med 17, 230 (2019).
https://doi.org/10.1186/s12916-019-1466-7
}
\seealso{
Other class probability metrics: 
\code{\link{cal_slope}()}
}
\author{
An Tang
}
\concept{class probability metrics}
